{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg96tvnl7BJj",
        "outputId": "32d364d0-bcf4-4905-acfc-4940b5f957af",
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, LlamaTokenizer, LlamaModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import json\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nqJ5ODSl7BJm",
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [],
      "source": [
        "#TODO\n",
        "#1 TRY ADDING BYLINE AND HEADER\n",
        "#2 TRY fine-tuning model somehow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDW5xFTP7BJm",
        "outputId": "fd46fcdf-ab26-43cc-8783-1943b1cd86c2",
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "utX2c30n7BJn",
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [],
      "source": [
        "#hyperparameters\n",
        "g_batch_size = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sOf2g0s7BJn",
        "outputId": "846ec24c-995d-4bbd-958e-da686b639aeb",
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x105a5e910>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "RandomSeed = 52\n",
        "random.seed(RandomSeed)\n",
        "torch.manual_seed(RandomSeed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghHsgDPd7BJn",
        "outputId": "38347c2f-7875-439f-c5c0-91d600251602",
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_name  = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "model.to(device)\n",
        "\n",
        "#model_name = \"meta-llama/Llama-3.2-1B\"\n",
        "#tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
        "#model = LlamaModel.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "2Q24BVaN7BJn",
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [],
      "source": [
        "def get_document_embedding(text):\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer.batch_encode_plus(\n",
        "            text,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            return_tensors='pt',\n",
        "            add_special_tokens=True)\n",
        "\n",
        "    # Move the inputs to the appropriate device (e.g., GPU if available)\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    # Get the hidden states from the model without gradients\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Use mean pooling over token embeddings to get a single document embedding\n",
        "    mean_pooled_embedding = outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move tensor to CPU and convert to NumPy\n",
        "    return mean_pooled_embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FmoHZEY87BJo",
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [],
      "source": [
        "def read_files_dataset(file_path):\n",
        "    documents = []\n",
        "    try:\n",
        "        # Try reading the file with utf-8 encoding, if it fails, fall back to ISO-8859-1\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            document = {}\n",
        "            in_text = False\n",
        "            in_headline = False\n",
        "            in_byline = False\n",
        "            in_doc = False\n",
        "\n",
        "            for line in file:\n",
        "                line = line.strip()\n",
        "\n",
        "                # Check if it's the start of a new document\n",
        "                if line.startswith(\"<DOCNO>\"):\n",
        "                    document['documentID'] = re.sub(r'<.*?>', '', line).strip()\n",
        "                elif line.startswith(\"<HEADLINE>\"):\n",
        "                    in_headline = True\n",
        "                    headline_parts = []\n",
        "                    while in_headline:\n",
        "                        line = next(file).strip()\n",
        "                        if line.startswith(\"</HEADLINE>\"):\n",
        "                            in_headline = False\n",
        "                        else:\n",
        "                            headline_parts.append(re.sub(r'<.*?>', '', line))\n",
        "                    #document['headline'] = ' '.join(headline_parts).strip()\n",
        "                elif line.startswith(\"<BYLINE>\"):\n",
        "                    in_byline = True\n",
        "                    byline_parts = []\n",
        "                    while in_byline:\n",
        "                        line = next(file).strip()\n",
        "                        if line.startswith(\"</BYLINE>\"):\n",
        "                            in_byline = False\n",
        "                        else:\n",
        "                            byline_parts.append(re.sub(r'<.*?>', '', line))\n",
        "                    #document['byLine'] = ' '.join(byline_parts).strip()\n",
        "                elif line.startswith(\"<TEXT>\"):\n",
        "                    in_text = True\n",
        "                    text_parts = []\n",
        "                    while in_text:\n",
        "                        line = next(file).strip()\n",
        "                        if line.startswith(\"</TEXT>\"):\n",
        "                            in_text = False\n",
        "                        else:\n",
        "                            text_parts.append(re.sub(r'<.*?>', '', line))\n",
        "                    document['text'] = ' '.join(text_parts).strip()\n",
        "\n",
        "                # End of a document\n",
        "                elif line.startswith(\"</DOC>\"):\n",
        "                    documents.append(document)\n",
        "                    document = {}\n",
        "\n",
        "    except UnicodeDecodeError as e:\n",
        "        documents=[]\n",
        "        print(f\"UnicodeDecodeError: {e}\")\n",
        "        print(f\"Trying ISO-8859-1 encoding for file: {file_path}\")\n",
        "        try:\n",
        "            # Try opening the file with ISO-8859-1 encoding if utf-8 fails\n",
        "            with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
        "                document = {}\n",
        "                in_text = False\n",
        "                in_headline = False\n",
        "                in_byline = False\n",
        "                in_doc = False\n",
        "\n",
        "                for line in file:\n",
        "                    line = line.strip()\n",
        "\n",
        "                    # Check if it's the start of a new document\n",
        "                    if line.startswith(\"<DOCNO>\"):\n",
        "                        document['documentID'] = re.sub(r'<.*?>', '', line).strip()\n",
        "                    elif line.startswith(\"<HEADLINE>\"):\n",
        "                        in_headline = True\n",
        "                        headline_parts = []\n",
        "                        while in_headline:\n",
        "                            line = next(file).strip()\n",
        "                            if line.startswith(\"</HEADLINE>\"):\n",
        "                                in_headline = False\n",
        "                            else:\n",
        "                                headline_parts.append(re.sub(r'<.*?>', '', line))\n",
        "                        #document['headline'] = ' '.join(headline_parts).strip()\n",
        "                    elif line.startswith(\"<BYLINE>\"):\n",
        "                        in_byline = True\n",
        "                        byline_parts = []\n",
        "                        while in_byline:\n",
        "                            line = next(file).strip()\n",
        "                            if line.startswith(\"</BYLINE>\"):\n",
        "                                in_byline = False\n",
        "                            else:\n",
        "                                byline_parts.append(re.sub(r'<.*?>', '', line))\n",
        "                        #document['byLine'] = ' '.join(byline_parts).strip()\n",
        "                    elif line.startswith(\"<TEXT>\"):\n",
        "                        in_text = True\n",
        "                        text_parts = []\n",
        "                        while in_text:\n",
        "                            line = next(file).strip()\n",
        "                            if line.startswith(\"</TEXT>\"):\n",
        "                                in_text = False\n",
        "                            else:\n",
        "                                text_parts.append(re.sub(r'<.*?>', '', line))\n",
        "                        document['text'] = ' '.join(text_parts).strip()\n",
        "\n",
        "                    # End of a document\n",
        "                    elif line.startswith(\"</DOC>\"):\n",
        "                        documents.append(document)\n",
        "                        document = {}\n",
        "\n",
        "        except Exception as ex:\n",
        "            print(f\"Failed to read file {file_path} with both UTF-8 and ISO-8859-1 encodings.\")\n",
        "            print(f\"Error: {ex}\")\n",
        "\n",
        "    return documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ApBDt4tl7BJo",
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [],
      "source": [
        "class DocumentBatchReader:\n",
        "    def __init__(self, file_paths, batch_size=g_batch_size):\n",
        "        self.file_paths = file_paths\n",
        "        self.batch_size = batch_size\n",
        "        self.current_file_index = 0\n",
        "\n",
        "    def _read_all_from_file(self, file_path):\n",
        "        # Read all documents from a single file\n",
        "        return read_files_dataset(file_path)\n",
        "\n",
        "    def get_next_batch(self):\n",
        "        # Initialize an empty list to store batches\n",
        "        batch = []\n",
        "        # Get up to 4 files in a single batch\n",
        "        for _ in range(4):\n",
        "            if self.current_file_index < len(self.file_paths):\n",
        "                file_path = self.file_paths[self.current_file_index]\n",
        "                print(file_path)\n",
        "                batch.extend(self._read_all_from_file(file_path))\n",
        "                # Move to the next file for the next batch call\n",
        "                self.current_file_index += 1\n",
        "            else:\n",
        "                break  # No more files to read\n",
        "        print(len(batch))\n",
        "        # Return batch if there are any files in it; otherwise, return None\n",
        "        return batch if batch else None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX8oU6rM7BJp",
        "outputId": "9e2cfe26-1233-47a2-be57-6c0e3dfc94ad",
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['./Data/latimes/la071790', './Data/latimes/la062989', './Data/latimes/la090890', './Data/latimes/la122989', './Data/latimes/la020790', './Data/latimes/la032890', './Data/latimes/la021689', './Data/latimes/la091989', './Data/latimes/la082790', './Data/latimes/la070689', './Data/latimes/la111390', './Data/latimes/la051390', './Data/latimes/la110289', './Data/latimes/la050289', './Data/latimes/la091389', './Data/latimes/la032290', './Data/latimes/la122389', './Data/latimes/la062389', './Data/latimes/la090290', './Data/latimes/la012690', './Data/latimes/la050889', './Data/latimes/la110889', './Data/latimes/la051990', './Data/latimes/la042789', './Data/latimes/la102789', './Data/latimes/la111990', './Data/latimes/la010990', './Data/latimes/la112789', './Data/latimes/la101990', './Data/latimes/la041990', './Data/latimes/la052789', './Data/latimes/la100889', './Data/latimes/la040889', './Data/latimes/la011889', './Data/latimes/la072389', './Data/latimes/la080290', './Data/latimes/la022290', './Data/latimes/la081389', './Data/latimes/la011289', './Data/latimes/la040289', './Data/latimes/la100289', './Data/latimes/la041390', './Data/latimes/la101390', './Data/latimes/la010390', './Data/latimes/la120689', './Data/latimes/la081989', './Data/latimes/la092790', './Data/latimes/la060689', './Data/latimes/la022890', './Data/latimes/la031689', './Data/latimes/la030790', './Data/latimes/la121790', './Data/latimes/la061790', './Data/latimes/la072989', './Data/latimes/la080890', './Data/latimes/la101790', './Data/latimes/la112989', './Data/latimes/la052989', './Data/latimes/la041790', './Data/latimes/la010790', './Data/latimes/la011689', './Data/latimes/la100689', './Data/latimes/la040689', './Data/latimes/la030390', './Data/latimes/la061390', './Data/latimes/la121390', './Data/latimes/la060289', './Data/latimes/la092390', './Data/latimes/la120289', './Data/latimes/la031289', './Data/latimes/la052389', './Data/latimes/la112389', './Data/latimes/la031889', './Data/latimes/la022690', './Data/latimes/la120889', './Data/latimes/la060889', './Data/latimes/la092990', './Data/latimes/la081789', './Data/latimes/la121990', './Data/latimes/la080690', './Data/latimes/la072789', './Data/latimes/la061990', './Data/latimes/la030990', './Data/latimes/la020990', './Data/latimes/la090690', './Data/latimes/la062789', './Data/latimes/la071990', './Data/latimes/la122789', './Data/latimes/la070889', './Data/latimes/la082990', './Data/latimes/la091789', './Data/latimes/la021889', './Data/latimes/la032690', './Data/latimes/la102389', './Data/latimes/la042389', './Data/latimes/la012290', './Data/latimes/la021289', './Data/latimes/la070289', './Data/latimes/la082390', './Data/latimes/la071390', './Data/latimes/la020390', './Data/latimes/la050689', './Data/latimes/la110689', './Data/latimes/la012890', './Data/latimes/la042989', './Data/latimes/la051790', './Data/latimes/la111790', './Data/latimes/la102989', './Data/latimes/la100790', './Data/latimes/la040790', './Data/latimes/la011790', './Data/latimes/la010689', './Data/latimes/la101689', './Data/latimes/la112890', './Data/latimes/la052890', './Data/latimes/la041689', './Data/latimes/la031390', './Data/latimes/la092289', './Data/latimes/la060390', './Data/latimes/la120390', './Data/latimes/la061289', './Data/latimes/la121289', './Data/latimes/la030289', './Data/latimes/la052290', './Data/latimes/la112290', './Data/latimes/la030889', './Data/latimes/la121889', './Data/latimes/la072690', './Data/latimes/la080789', './Data/latimes/la061889', './Data/latimes/la120990', './Data/latimes/la092889', './Data/latimes/la060990', './Data/latimes/la081690', './Data/latimes/la031990', './Data/latimes/la022789', './Data/latimes/la021990', './Data/latimes/la032789', './Data/latimes/la082889', './Data/latimes/la070990', './Data/latimes/la091690', './Data/latimes/la062690', './Data/latimes/la090789', './Data/latimes/la071889', './Data/latimes/la122690', './Data/latimes/la020889', './Data/latimes/la012389', './Data/latimes/la102290', './Data/latimes/la042290', './Data/latimes/la020289', './Data/latimes/la071289', './Data/latimes/la082289', './Data/latimes/la070390', './Data/latimes/la021390', './Data/latimes/la042890', './Data/latimes/la051689', './Data/latimes/la111689', './Data/latimes/la102890', './Data/latimes/la012989', './Data/latimes/la050790', './Data/latimes/la110790', './Data/latimes/la091890', './Data/latimes/la070790', './Data/latimes/la082689', './Data/latimes/la032989', './Data/latimes/la021790', './Data/latimes/la020689', './Data/latimes/la071689', './Data/latimes/la090989', './Data/latimes/la062890', './Data/latimes/la122890', './Data/latimes/la110390', './Data/latimes/la050390', './Data/latimes/la111289', './Data/latimes/la051289', './Data/latimes/la122290', './Data/latimes/la090389', './Data/latimes/la062290', './Data/latimes/la032389', './Data/latimes/la091290', './Data/latimes/la051889', './Data/latimes/la042690', './Data/latimes/la102690', './Data/latimes/la111889', './Data/latimes/la050990', './Data/latimes/la110990', './Data/latimes/la012789', './Data/latimes/la011990', './Data/latimes/la100990', './Data/latimes/la040990', './Data/latimes/la112690', './Data/latimes/la101889', './Data/latimes/la041889', './Data/latimes/la052690', './Data/latimes/la010889', './Data/latimes/la081290', './Data/latimes/la022389', './Data/latimes/la080389', './Data/latimes/la072290', './Data/latimes/la010289', './Data/latimes/la041289', './Data/latimes/la101289', './Data/latimes/la040390', './Data/latimes/la100390', './Data/latimes/la011390', './Data/latimes/la121689', './Data/latimes/la061689', './Data/latimes/la080989', './Data/latimes/la072890', './Data/latimes/la030689', './Data/latimes/la031790', './Data/latimes/la120790', './Data/latimes/la081890', './Data/latimes/la060790', './Data/latimes/la092689', './Data/latimes/la052489', './Data/latimes/la112489', './Data/latimes/la081089', './Data/latimes/la073190', './Data/latimes/la022190', './Data/latimes/la080190', './Data/latimes/la072089', './Data/latimes/la101090', './Data/latimes/la041090', './Data/latimes/la100189', './Data/latimes/la040189', './Data/latimes/la011189', './Data/latimes/la061490', './Data/latimes/la121490', './Data/latimes/la030490', './Data/latimes/la031589', './Data/latimes/la060589', './Data/latimes/la092490', './Data/latimes/la120589', './Data/latimes/la070589', './Data/latimes/la082490', './Data/latimes/la021589', './Data/latimes/la020490', './Data/latimes/la071490', './Data/latimes/la050189', './Data/latimes/la110189', './Data/latimes/la051090', './Data/latimes/la111090', './Data/latimes/la090190', './Data/latimes/la062089', './Data/latimes/la122089', './Data/latimes/la033089', './Data/latimes/la032190', './Data/latimes/la091089', './Data/latimes/la123190', './Data/latimes/la102489', './Data/latimes/la042489', './Data/latimes/la012590', './Data/latimes/la032590', './Data/latimes/la091489', './Data/latimes/la122489', './Data/latimes/la062489', './Data/latimes/la090590', './Data/latimes/la103190', './Data/latimes/la012190', './Data/latimes/la013089', './Data/latimes/la042089', './Data/latimes/la102089', './Data/latimes/la083189', './Data/latimes/la071090', './Data/latimes/la082090', './Data/latimes/la070189', './Data/latimes/la021189', './Data/latimes/la111490', './Data/latimes/la051490', './Data/latimes/la110589', './Data/latimes/la050589', './Data/latimes/la040589', './Data/latimes/la100589', './Data/latimes/la011589', './Data/latimes/la010490', './Data/latimes/la041490', './Data/latimes/la101490', './Data/latimes/la031189', './Data/latimes/la120189', './Data/latimes/la092090', './Data/latimes/la060189', './Data/latimes/la121090', './Data/latimes/la061090', './Data/latimes/la112089', './Data/latimes/la052089', './Data/latimes/la053190', './Data/latimes/la072489', './Data/latimes/la080590', './Data/latimes/la081489', './Data/latimes/la022590', './Data/latimes/la122590', './Data/latimes/la090489', './Data/latimes/la062590', './Data/latimes/la091590', './Data/latimes/la032489', './Data/latimes/la042190', './Data/latimes/la102190', './Data/latimes/la013190', './Data/latimes/la012089', './Data/latimes/la043089', './Data/latimes/la103089', './Data/latimes/la021090', './Data/latimes/la082189', './Data/latimes/la071189', './Data/latimes/la083090', './Data/latimes/la020189', './Data/latimes/la110490', './Data/latimes/la050490', './Data/latimes/la111589', './Data/latimes/la051589', './Data/latimes/la041589', './Data/latimes/la101589', './Data/latimes/la010589', './Data/latimes/la011490', './Data/latimes/la040490', './Data/latimes/la100490', './Data/latimes/la030189', './Data/latimes/la121189', './Data/latimes/la061189', './Data/latimes/la093090', './Data/latimes/la092189', './Data/latimes/la031090', './Data/latimes/la113089', './Data/latimes/la053089', './Data/latimes/la112190', './Data/latimes/la052190', './Data/latimes/la022489', './Data/latimes/la081590', './Data/latimes/la080489', './Data/latimes/la072590', './Data/latimes/la052590', './Data/latimes/la112590', './Data/latimes/la072190', './Data/latimes/la022089', './Data/latimes/la073089', './Data/latimes/la081190', './Data/latimes/la011090', './Data/latimes/la101189', './Data/latimes/la041189', './Data/latimes/la010189', './Data/latimes/la092589', './Data/latimes/la060490', './Data/latimes/la120490', './Data/latimes/la031490', './Data/latimes/la030589', './Data/latimes/la061589', './Data/latimes/la121589', './Data/latimes/la071589', './Data/latimes/la020589', './Data/latimes/la021490', './Data/latimes/la082589', './Data/latimes/la070490', './Data/latimes/la051189', './Data/latimes/la111189', './Data/latimes/la063089', './Data/latimes/la091190', './Data/latimes/la123089', './Data/latimes/la032089', './Data/latimes/la033190', './Data/latimes/la062190', './Data/latimes/la122190', './Data/latimes/la012489', './Data/latimes/la102590', './Data/latimes/la042590', './Data/latimes/la031489', './Data/latimes/la120489', './Data/latimes/la060489', './Data/latimes/la092590', './Data/latimes/la121590', './Data/latimes/la061590', './Data/latimes/la030590', './Data/latimes/la011089', './Data/latimes/la010190', './Data/latimes/la041190', './Data/latimes/la101190', './Data/latimes/la072189', './Data/latimes/la081189', './Data/latimes/la073090', './Data/latimes/la022090', './Data/latimes/la112589', './Data/latimes/la052589', './Data/latimes/la012490', './Data/latimes/la042589', './Data/latimes/la102589', './Data/latimes/la032090', './Data/latimes/la123090', './Data/latimes/la091189', './Data/latimes/la063090', './Data/latimes/la122189', './Data/latimes/la062189', './Data/latimes/la033189', './Data/latimes/la111190', './Data/latimes/la051190', './Data/latimes/la020590', './Data/latimes/la071590', './Data/latimes/la070489', './Data/latimes/la082590', './Data/latimes/la021489', './Data/latimes/la050489', './Data/latimes/la110489', './Data/latimes/la051590', './Data/latimes/la111590', './Data/latimes/la082190', './Data/latimes/la021089', './Data/latimes/la020190', './Data/latimes/la083089', './Data/latimes/la071190', './Data/latimes/la013189', './Data/latimes/la102189', './Data/latimes/la042189', './Data/latimes/la103090', './Data/latimes/la043090', './Data/latimes/la012090', './Data/latimes/la062589', './Data/latimes/la090490', './Data/latimes/la122589', './Data/latimes/la032490', './Data/latimes/la091589', './Data/latimes/la081589', './Data/latimes/la022490', './Data/latimes/la072589', './Data/latimes/la080490', './Data/latimes/la053090', './Data/latimes/la113090', './Data/latimes/la052189', './Data/latimes/la112189', './Data/latimes/la093089', './Data/latimes/la061190', './Data/latimes/la121190', './Data/latimes/la030190', './Data/latimes/la031089', './Data/latimes/la092190', './Data/latimes/la010590', './Data/latimes/la101590', './Data/latimes/la041590', './Data/latimes/la100489', './Data/latimes/la040489', './Data/latimes/la011489', './Data/latimes/la051489', './Data/latimes/la111489', './Data/latimes/la050590', './Data/latimes/la110590', './Data/latimes/la071089', './Data/latimes/la083190', './Data/latimes/la021190', './Data/latimes/la070190', './Data/latimes/la082089', './Data/latimes/la012189', './Data/latimes/la103189', './Data/latimes/la102090', './Data/latimes/la042090', './Data/latimes/la013090', './Data/latimes/la091490', './Data/latimes/la032589', './Data/latimes/la090589', './Data/latimes/la062490', './Data/latimes/la122490', './Data/latimes/la080589', './Data/latimes/la072490', './Data/latimes/la022589', './Data/latimes/la081490', './Data/latimes/la052090', './Data/latimes/la112090', './Data/latimes/la053189', './Data/latimes/la060190', './Data/latimes/la092089', './Data/latimes/la120190', './Data/latimes/la031190', './Data/latimes/la061089', './Data/latimes/la121089', './Data/latimes/la011590', './Data/latimes/la100590', './Data/latimes/la040590', './Data/latimes/la101489', './Data/latimes/la041489', './Data/latimes/la010489', './Data/latimes/la030489', './Data/latimes/la121489', './Data/latimes/la061489', './Data/latimes/la120590', './Data/latimes/la092489', './Data/latimes/la060590', './Data/latimes/la031590', './Data/latimes/la041089', './Data/latimes/la101089', './Data/latimes/la011190', './Data/latimes/la040190', './Data/latimes/la100190', './Data/latimes/la022189', './Data/latimes/la073189', './Data/latimes/la081090', './Data/latimes/la072090', './Data/latimes/la080189', './Data/latimes/la112490', './Data/latimes/la052490', './Data/latimes/la042490', './Data/latimes/la102490', './Data/latimes/la012589', './Data/latimes/la033090', './Data/latimes/la122090', './Data/latimes/la062090', './Data/latimes/la090189', './Data/latimes/la123189', './Data/latimes/la091090', './Data/latimes/la032189', './Data/latimes/la110190', './Data/latimes/la050190', './Data/latimes/la111089', './Data/latimes/la051089', './Data/latimes/la021590', './Data/latimes/la082489', './Data/latimes/la070590', './Data/latimes/la071489', './Data/latimes/la020489', './Data/latimes/la102689', './Data/latimes/la111890', './Data/latimes/la051890', './Data/latimes/la042689', './Data/latimes/la012790', './Data/latimes/la110989', './Data/latimes/la050989', './Data/latimes/la062289', './Data/latimes/la090390', './Data/latimes/la122289', './Data/latimes/la091289', './Data/latimes/la032390', './Data/latimes/la050389', './Data/latimes/la110389', './Data/latimes/la051290', './Data/latimes/la111290', './Data/latimes/la032990', './Data/latimes/la021789', './Data/latimes/la091889', './Data/latimes/la082690', './Data/latimes/la070789', './Data/latimes/la122889', './Data/latimes/la071690', './Data/latimes/la062889', './Data/latimes/la090990', './Data/latimes/la020690', './Data/latimes/la030690', './Data/latimes/la061690', './Data/latimes/la072889', './Data/latimes/la080990', './Data/latimes/la121690', './Data/latimes/la081889', './Data/latimes/la092690', './Data/latimes/la060789', './Data/latimes/la120789', './Data/latimes/la031789', './Data/latimes/la101290', './Data/latimes/la041290', './Data/latimes/la010290', './Data/latimes/la011389', './Data/latimes/la100389', './Data/latimes/la040389', './Data/latimes/la022390', './Data/latimes/la081289', './Data/latimes/la072289', './Data/latimes/la080390', './Data/latimes/la040989', './Data/latimes/la100989', './Data/latimes/la011989', './Data/latimes/la010890', './Data/latimes/la041890', './Data/latimes/la052689', './Data/latimes/la112689', './Data/latimes/la101890', './Data/latimes/la080790', './Data/latimes/la072689', './Data/latimes/la061890', './Data/latimes/la121890', './Data/latimes/la030890', './Data/latimes/la031989', './Data/latimes/la022790', './Data/latimes/la060989', './Data/latimes/la092890', './Data/latimes/la081689', './Data/latimes/la120989', './Data/latimes/la112289', './Data/latimes/la052289', './Data/latimes/la120389', './Data/latimes/la060389', './Data/latimes/la092290', './Data/latimes/la031389', './Data/latimes/la030290', './Data/latimes/la121290', './Data/latimes/la061290', './Data/latimes/la011789', './Data/latimes/la040789', './Data/latimes/la100789', './Data/latimes/la052889', './Data/latimes/la041690', './Data/latimes/la101690', './Data/latimes/la112889', './Data/latimes/la010690', './Data/latimes/la111690', './Data/latimes/la102889', './Data/latimes/la042889', './Data/latimes/la051690', './Data/latimes/la110789', './Data/latimes/la050789', './Data/latimes/la012990', './Data/latimes/la071290', './Data/latimes/la020290', './Data/latimes/la021389', './Data/latimes/la070389', './Data/latimes/la082290', './Data/latimes/la012390', './Data/latimes/la042289', './Data/latimes/la102289', './Data/latimes/la070989', './Data/latimes/la082890', './Data/latimes/la091689', './Data/latimes/la021989', './Data/latimes/la032790', './Data/latimes/la020890', './Data/latimes/la122689', './Data/latimes/la090790', './Data/latimes/la062689', './Data/latimes/la071890', './Data/latimes/la092989', './Data/latimes/la060890', './Data/latimes/la081790', './Data/latimes/la120890', './Data/latimes/la031890', './Data/latimes/la022689', './Data/latimes/la030989', './Data/latimes/la072790', './Data/latimes/la080689', './Data/latimes/la061989', './Data/latimes/la121989', './Data/latimes/la112390', './Data/latimes/la052390', './Data/latimes/la121389', './Data/latimes/la061389', './Data/latimes/la030389', './Data/latimes/la031290', './Data/latimes/la120290', './Data/latimes/la092389', './Data/latimes/la060290', './Data/latimes/la010789', './Data/latimes/la052990', './Data/latimes/la041789', './Data/latimes/la101789', './Data/latimes/la112990', './Data/latimes/la040690', './Data/latimes/la100690', './Data/latimes/la011690', './Data/latimes/la012889', './Data/latimes/la110690', './Data/latimes/la050690', './Data/latimes/la111789', './Data/latimes/la102990', './Data/latimes/la042990', './Data/latimes/la051789', './Data/latimes/la082389', './Data/latimes/la070290', './Data/latimes/la021290', './Data/latimes/la020389', './Data/latimes/la071389', './Data/latimes/la042390', './Data/latimes/la102390', './Data/latimes/la012289', './Data/latimes/la122790', './Data/latimes/la062790', './Data/latimes/la090689', './Data/latimes/la071989', './Data/latimes/la020989', './Data/latimes/la021890', './Data/latimes/la032689', './Data/latimes/la082989', './Data/latimes/la070890', './Data/latimes/la091790', './Data/latimes/la110890', './Data/latimes/la050890', './Data/latimes/la012689', './Data/latimes/la102790', './Data/latimes/la111989', './Data/latimes/la051989', './Data/latimes/la042790', './Data/latimes/la032289', './Data/latimes/la091390', './Data/latimes/la090289', './Data/latimes/la062390', './Data/latimes/la122390', './Data/latimes/la051389', './Data/latimes/la111389', './Data/latimes/la050290', './Data/latimes/la110290', './Data/latimes/la020789', './Data/latimes/la122990', './Data/latimes/la071789', './Data/latimes/la090889', './Data/latimes/la062990', './Data/latimes/la091990', './Data/latimes/la070690', './Data/latimes/la082789', './Data/latimes/la032889', './Data/latimes/la021690', './Data/latimes/la022889', './Data/latimes/la031690', './Data/latimes/la081990', './Data/latimes/la060690', './Data/latimes/la092789', './Data/latimes/la120690', './Data/latimes/la061789', './Data/latimes/la080889', './Data/latimes/la072990', './Data/latimes/la121789', './Data/latimes/la030789', './Data/latimes/la100290', './Data/latimes/la040290', './Data/latimes/la011290', './Data/latimes/la010389', './Data/latimes/la101389', './Data/latimes/la041389', './Data/latimes/la080289', './Data/latimes/la072390', './Data/latimes/la081390', './Data/latimes/la022289', './Data/latimes/la041989', './Data/latimes/la052790', './Data/latimes/la112790', './Data/latimes/la101989', './Data/latimes/la010989', './Data/latimes/la011890', './Data/latimes/la040890', './Data/latimes/la100890']\n",
            "./Data/latimes/la071790\n",
            "./Data/latimes/la062989\n",
            "./Data/latimes/la090890\n",
            "./Data/latimes/la122989\n",
            "734\n",
            "ABC 734\n",
            "GETTING EMBEDDINGS\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# List all your files (assuming they are XML files and stored in a directory)\n",
        "#file_paths = [f\"./drive/MyDrive/Data/fbis/{file_name}\" for file_name in os.listdir('./drive/MyDrive/Data/fbis/') if not file_name.endswith('.txt')]\n",
        "file_paths = [f\"./Data/latimes/{file_name}\" for file_name in os.listdir('./Data/latimes/') if not file_name.endswith('.txt')]\n",
        "print(file_paths)\n",
        "\n",
        "# Create a batch reader instance\n",
        "batch_reader = DocumentBatchReader(file_paths, batch_size=g_batch_size)\n",
        "output_file_embeddings = './Embeddings/latimes/latimes-embeddings_'\n",
        "output_file_documents = './Embeddings/latimes/latimes-documents_'\n",
        "counter = 1\n",
        "\n",
        "# Prepare lists to store documentIDs and texts separately\n",
        "document_ids_data = []\n",
        "texts_data = []\n",
        "\n",
        "while True:\n",
        "    batch = batch_reader.get_next_batch()\n",
        "    if batch:\n",
        "        # Step 1: Split the documents into two lists\n",
        "        document_ids = []\n",
        "        texts=[]\n",
        "        for doc in batch:\n",
        "            document_ids.append(doc['documentID'])\n",
        "            if 'text' in doc:\n",
        "                texts.append(doc['text'])\n",
        "            else:\n",
        "                texts.append(\"\")\n",
        "        print(\"ABC\",len(texts))\n",
        "        print(\"GETTING EMBEDDINGS\")\n",
        "        # Step 2: Get embeddings for the text batch\n",
        "        embeddings = get_document_embedding(texts)\n",
        "        print(\"GETTING EMBEDDINGS TAKEN\")\n",
        "        # Step 3: Store documentID and embedding separately\n",
        "        document_ids_data.extend(document_ids)\n",
        "        texts_data.extend(embeddings)\n",
        "        print(len(document_ids_data),len(texts_data))\n",
        "        # Save to files if the data exceeds 10,000 entries\n",
        "        if len(document_ids_data) > 10000:\n",
        "            # Save documentIDs\n",
        "            output_file_ids = output_file_documents + str(counter) + '.txt'\n",
        "            with open(output_file_ids, 'w') as f:\n",
        "                for doc in document_ids_data:\n",
        "                  f.write(doc+\"\\n\")\n",
        "\n",
        "            # Save embeddings\n",
        "            output_file_texts = output_file_embeddings + str(counter) + '.txt'\n",
        "            with open(output_file_texts, 'w') as f:\n",
        "                for doc in texts_data:\n",
        "                  f.write(\" \".join(map(str, doc)) + \"\\n\")\n",
        "\n",
        "            print(f\"Document IDs saved to {output_file_ids}.\")\n",
        "            print(f\"Embeddings saved to {output_file_texts}.\")\n",
        "\n",
        "            # Increment counter and clear lists\n",
        "            counter += 1\n",
        "            document_ids_data = []\n",
        "            texts_data = []\n",
        "    else:\n",
        "        # Save documentIDs\n",
        "        output_file_ids = output_file_documents + str(counter) + '.txt'\n",
        "        with open(output_file_ids, 'w') as f:\n",
        "            for doc in document_ids_data:\n",
        "                  f.write(doc+\"\\n\")\n",
        "\n",
        "        # Save embeddings\n",
        "        output_file_texts = output_file_embeddings + str(counter) + '.txt'\n",
        "        with open(output_file_texts, 'w') as f:\n",
        "            for doc in texts_data:\n",
        "                  f.write(\" \".join(map(str, doc)) + \"\\n\")\n",
        "\n",
        "        print(f\"Document IDs saved to {output_file_ids}.\")\n",
        "        print(f\"Embeddings saved to {output_file_texts}.\")\n",
        "        print(\"No more documents available.\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trNIKmfa7BJp",
        "outputId": "b6b70c48-96ad-4332-dd13-75d232badacd",
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'batch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m \u001b[43mbatch\u001b[49m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(doc)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
          ]
        }
      ],
      "source": [
        "for doc in batch:\n",
        "    print(doc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9hETQHQ7BJp",
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(vec1, vec2):\n",
        "    print(np.shape(vec1),np.shape(vec2))\n",
        "    # Calculate the dot product of the vectors\n",
        "    dot_product = np.dot(vec1, vec2)\n",
        "    # Calculate the L2 norms (magnitudes) of the vectors\n",
        "    norm_vec1 = np.linalg.norm(vec1)\n",
        "    norm_vec2 = np.linalg.norm(vec2)\n",
        "    # Compute cosine similarity\n",
        "    return dot_product / (norm_vec1 * norm_vec2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZinDBLZD7BJp",
        "outputId": "eef0457b-c5c9-4135-cc2f-841e039fb85d",
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(768,) (768,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "np.float32(0.75074565)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cosine_similarity(embeddings[0].squeeze(),query_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sgK7O2Bs7BJq",
        "outputId": "91c4fd96-8eb0-4124-8187-02006658dd6b",
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of <DOC> tags: 130474\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def count_doc_tags_in_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "        content = file.read()\n",
        "    return content.count('<DOC>')\n",
        "\n",
        "\n",
        "def count_doc_tags_in_folder(folder_path):\n",
        "    total_count = 0\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        if os.path.isfile(file_path):\n",
        "            total_count += count_doc_tags_in_file(file_path)\n",
        "    return total_count\n",
        "\n",
        "folder_path = './Data/fbis/'  # Replace with your folder path\n",
        "total_doc_tags = 0\n",
        "total_doc_tags += count_doc_tags_in_folder(folder_path)\n",
        "print(f\"Total number of <DOC> tags: {total_doc_tags}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dFW2PNr7BJq",
        "outputId": "432a413a-9673-414a-cbd4-1d36c7db19ee",
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'content' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbeddings/fbis/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     33\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmbeddings/fbis/\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;241m+\u001b[39m i\n\u001b[0;32m---> 34\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mcount_document_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of documentID\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms in the file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[13], line 10\u001b[0m, in \u001b[0;36mcount_document_ids\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Try to parse the content as a list of JSON objects\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Load the content as a list (it should be a list of dictionaries or lists of dictionaries)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[43mcontent\u001b[49m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Initialize a counter for documentID\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     document_id_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'content' is not defined"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "def count_document_ids(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        content = file.read()\n",
        "    # Try to parse the content as a list of JSON objects\n",
        "    try:\n",
        "        # Load the content as a list (it should be a list of dictionaries or lists of dictionaries)\n",
        "        data = json.loads(content)\n",
        "        # Initialize a counter for documentID\n",
        "        document_id_count = 0\n",
        "        data = list(data)\n",
        "        print(data[0])\n",
        "        # Iterate over the structure and count occurrences of \"documentID\"\n",
        "        if isinstance(data, list):  # Ensure the root structure is a list\n",
        "            for item in data:\n",
        "                if isinstance(item, list):  # Nested lists\n",
        "                    for sub_item in item:\n",
        "                        if isinstance(sub_item, dict) and 'documentID' in sub_item:\n",
        "                            document_id_count += 1\n",
        "                elif isinstance(item, dict) and 'documentID' in item:\n",
        "                    document_id_count += 1\n",
        "\n",
        "        return document_id_count\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Error parsing JSON.\")\n",
        "        return 0\n",
        "count = 0\n",
        "# Example usage for a single file\n",
        "for i in os.listdir(\"Embeddings/fbis/\"):\n",
        "    file_path = 'Embeddings/fbis/'  + i\n",
        "    count += count_document_ids(file_path)\n",
        "    print(f\"Number of documentID's in the file: {count}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unjTeF1W7BJq",
        "outputId": "8085324a-ae84-4ace-d418-5772ea0e2c7f",
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.3-cp39-cp39-macosx_11_0_arm64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 6.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tzdata>=2022.7\n",
            "  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
            "\u001b[K     |████████████████████████████████| 346 kB 2.3 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /Users/pratyushgaurav/Library/Python/3.9/lib/python/site-packages (from pandas) (2.0.2)\n",
            "Collecting pytz>=2020.1\n",
            "  Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 5.6 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Users/pratyushgaurav/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
            "Installing collected packages: tzdata, pytz, pandas\n",
            "Successfully installed pandas-2.2.3 pytz-2024.2 tzdata-2024.2\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
            "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZL-0ZSQ57BJq",
        "outputId": "2bcdf29f-a8c6-4b9f-a46b-1eb7efc57ce2",
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "133108\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "count = 0\n",
        "# Load the file content\n",
        "for i in os.listdir('./Embeddings/fbis/'):\n",
        "    with open('./Embeddings/fbis/' + i, 'r') as file:\n",
        "        content = file.read()\n",
        "\n",
        "    # Count occurrences of \"documentID\"\n",
        "    count += content.count(\"documentID\")\n",
        "print(count)\n",
        "\n",
        "133108\n",
        "130474"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
